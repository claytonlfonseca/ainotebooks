{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Perplexidade\n",
    "\n",
    "Uma das formas de avaliar um modelo de linguagem é calculando a sua perplexidade.\n",
    "\n",
    "Dado um conjunto de testes com $m$ frases ($s_1, s_2, ..., s_m$), um modelo é bom se ele atribui probabilidade alta às frases do conjunto de testes, em outras palavras, se ele consegue prever as frases.\n",
    "\n",
    "Vamos utilizar um dataset com os romances de Machado de Assis. O código abaixo lê o arquivo e extrai o conteúdo textual das obras, excluindo os nomes dos capítulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath = \"machadodeassiscorpus.txt\"\n",
    "text = \"\"\n",
    "\n",
    "with open(filepath) as corpus:\n",
    "    for line in corpus:\n",
    "        if not (line.startswith(\"#\") or line.startswith(\"%\")):\n",
    "            text += line\n",
    "            \n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os primeiros 100 caracteres do dataset são:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "naquele dia, — já lá vão dez anos! — o dr. félix levantou-se tarde, abriu a janela e cumprimentou \n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As probabilidades são calculadas usando tokens do texto. Para quebrar o texto em tokens utilizaremos a biblioteca NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os 50 primeiros tokens são:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['naquele', 'dia', ',', '—', 'já', 'lá', 'vão', 'dez', 'anos', '!', '—', 'o', 'dr.', 'félix', 'levantou-se', 'tarde', ',', 'abriu', 'a', 'janela', 'e', 'cumprimentou', 'o', 'sol', '.', 'o', 'dia', 'estava', 'esplêndido', ';', 'uma', 'fresca', 'bafagem', 'do', 'mar', 'vinha', 'quebrar', 'um', 'pouco', 'os', 'ardores', 'do', 'estio', ';', 'algumas', 'raras', 'nuvenzinhas', 'brancas', ',', 'finas']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos agrupar os tokens em frases para calcular as probabilidades. Nesse caso, consideraremos o fim de uma frase quando o token for \".\", \"?\" ou \"!\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "temp_sentence = []\n",
    "\n",
    "for token in tokens:\n",
    "    temp_sentence.append(token)\n",
    "\n",
    "    if token in \".!?\":\n",
    "        sentences.append(temp_sentence)\n",
    "        temp_sentence = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos as duas primeiras frases retornadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naquele dia , — já lá vão dez anos !\n",
      "— o dr. félix levantou-se tarde , abriu a janela e cumprimentou o sol .\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(sentences[0]))\n",
    "print(\" \".join(sentences[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular a probabilidade que o modelo atribui a todo conjunto de testes multiplicaremos as probabilidades atribuídas a cada frase:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(teste) = \\prod_{i=1}^{m}p(s_i)\n",
    "\\end{equation*}\n",
    "\n",
    "O valor calculado rapidamente se torna muito pequeno, podendo causar problemas de underflow. Por isso, usaremos o $\\log_2$ da probabilidade. Como $\\log (a*b) = \\log a + \\log b$, temos:\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "\\log_2 P(teste) = \\sum_{i=1}^{m}\\log_2 p(s_i)\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente vamos utilizar unigramas. Com isso, a probabilidade de um token $w_i$ é calculada assim:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(w_i | w_1 w_2 ... w_{i-1}) = P(w_i)\n",
    "\\end{equation*}\n",
    "\n",
    "Dessa forma, precisamos contar a ocorrência de cada token no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigrams_count = {}\n",
    "\n",
    "for token in tokens:\n",
    "    unigrams_count[token] = unigrams_count.get(token, 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver no resultado da contagem, por exemplo, quantas vezes a palavra \"dia\" e \"mulher\" aparecem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem da palavra 'dia': 776\n",
      "Contagem da palavra 'mulher': 380\n"
     ]
    }
   ],
   "source": [
    "print(\"Contagem da palavra 'dia': {}\".format(unigrams_count[\"dia\"]))\n",
    "print(\"Contagem da palavra 'mulher': {}\".format(unigrams_count[\"mulher\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probabilidade de uma frase é a multiplicação das probabilidades dos seus tokens. Nesse caso, se a frase tem $n$ tokens, temos:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(s) = P(w_1) * P(w_2) * ... * P(w_n)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entretanto, dependendo da frase, esse valor já pode sofrer com problemas de underflow. Por isso, vamos usar o $\\log_2$ nesses cálculos.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\log_2 P(s) = \\log_2 P(w_1) + \\log_2 P(w_2) + ... + \\log_2 P(w_n)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular a probabilidade de uma frase definiremos uma função. Ela vai receber a frase, os tokens e as contagens como parâmetros. \n",
    "\n",
    "As contagens podem ser computadas através dos tokens, mas, por questões de desempenho, vamos passar para função as contagens que já temos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "def sentence_unigram_prob(sentence, tokens, counts):\n",
    "    total = len(tokens)\n",
    "\n",
    "    prob = 0\n",
    "    for token in sentence:\n",
    "        token_prob = counts[token]/total\n",
    "        prob += log2(token_prob)\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando com frases do dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_2 da probabilidade da frase 'naquele dia , — já lá vão dez anos !': -94.47081343852943\n",
      "Log_2 da probabilidade da frase '— o dr. félix levantou-se tarde , abriu a janela e cumprimentou o sol .': -136.40681288913103\n"
     ]
    }
   ],
   "source": [
    "print(\"Log_2 da probabilidade da frase '{}': {}\".format(\" \".join(sentences[0]),\n",
    "    sentence_unigram_prob(sentences[0], tokens, unigrams_count)))\n",
    "\n",
    "print(\"Log_2 da probabilidade da frase '{}': {}\".format(\" \".join(sentences[1]),\n",
    "    sentence_unigram_prob(sentences[1], tokens, unigrams_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos calcular o $\\log_2$ da probabilidade que o modelo atribui ao conjunto de testes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5982709.342760975\n"
     ]
    }
   ],
   "source": [
    "unigram_prob = 0\n",
    "for sentence in sentences:\n",
    "    sentence_prob = sentence_unigram_prob(sentence, tokens, unigrams_count)\n",
    "    unigram_prob += sentence_prob\n",
    "    \n",
    "print(unigram_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dataset com muitas frases tende a possuir uma probabilidade menor que um com poucas, pois mais valores de probabilidade são multiplicados. Por isso, para normalizar o resultado, vamos tirar uma média dividindo o resultado pelo número de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.498097815888574\n"
     ]
    }
   ],
   "source": [
    "total_tokens = len(tokens)\n",
    "mean = unigram_prob/total_tokens\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, vamos elevar 2 ao valor negativo da média. Assim, a perplexidade será um número positivo e quanto menor ela for, maior é a probabilidade atribuída pelo modelo.\n",
    "\n",
    "\\begin{equation*}\n",
    "Perplexidade = 2^{-\\frac{1}{M}\\sum_{i=1}^{m}\\log_2 p(s_i)}\n",
    "\\end{equation*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "723.123281725287\n"
     ]
    }
   ],
   "source": [
    "perplexity = 2**(-1*(mean))\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo unigrama tende a ser ruim em prever probabilidades, pois cada token é avaliado individualmente, sem considerar tokens anteriores. Espera-se que um modelo bigrama ou trigrama tenham desempenho melhores respectivamente. Assim, vamos calcular a perplexidade usando bigramas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo é fazer a contagem dos bigramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bigrams_count = {}\n",
    "\n",
    "for i in range(1, len(tokens)):\n",
    "    pair = (tokens[i-1], tokens[i])\n",
    "    bigrams_count[pair] = bigrams_count.get(pair, 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver no resultado da contagem, por exemplo, quantas vezes os pares (\"o\", \"dia\") e (\"a\", \"mulher\") aparecem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem do par ('o', 'dia'): 62\n",
      "Contagem da par ('a', 'mulher'): 139\n"
     ]
    }
   ],
   "source": [
    "print(\"Contagem do par ('o', 'dia'): {}\".format(bigrams_count[(\"o\", \"dia\")]))\n",
    "print(\"Contagem da par ('a', 'mulher'): {}\".format(bigrams_count[(\"a\", \"mulher\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando bigramas, a probabilidade de um token $w_i$ é calculada assim:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(w_i | w_1 w_2 ... w_{i-1}) = P(w_i | w_{i-1})\n",
    "\\end{equation*}\n",
    "\n",
    "Com isso, a probabilidade de uma frase com $n$ tokens é:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(s) = P(w_1) * P(w_2 | w_1) * P(w_3 | w_2) ... * P(w_n | w_{n-1})\n",
    "\\end{equation*}\n",
    "\n",
    "Sendo\n",
    "\n",
    "\\begin{equation*}\n",
    "P(b | a) = \\frac{count(a, b)}{count(b)}\n",
    "\\end{equation*}\n",
    "\n",
    "Calcularemos o $\\log_2$ das probabilidades usando a função a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_bigram_prob(sentence, tokens, unigram_counts, bigram_counts):\n",
    "    total = len(tokens)\n",
    "    \n",
    "    prob = log2(unigram_counts[tokens[0]]/total)\n",
    "\n",
    "    for i in range(1, len(sentence)):\n",
    "        pair = (tokens[i-1], tokens[i])\n",
    "        token_prob = bigram_counts[pair]/unigram_counts[tokens[i-1]]\n",
    "\n",
    "        prob += log2(token_prob)\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando com o dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_2 da probabilidade da frase 'naquele dia , — já lá vão dez anos !': -55.62808216458857\n",
      "Log_2 da probabilidade da frase '— o dr. félix levantou-se tarde , abriu a janela e cumprimentou o sol .': -83.96472522394838\n"
     ]
    }
   ],
   "source": [
    "print(\"Log_2 da probabilidade da frase '{}': {}\".format(\" \".join(sentences[0]),\n",
    "    sentence_bigram_prob(sentences[0], tokens, unigrams_count, bigrams_count)))\n",
    "\n",
    "print(\"Log_2 da probabilidade da frase '{}': {}\".format(\" \".join(sentences[1]),\n",
    "    sentence_bigram_prob(sentences[1], tokens, unigrams_count, bigrams_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos calcular o $\\log_2$ da probabilidade que o modelo bigrama atribui ao conjunto de testes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3664774.817399596\n"
     ]
    }
   ],
   "source": [
    "bigram_prob = 0\n",
    "for sentence in sentences:\n",
    "    sentence_prob = sentence_bigram_prob(sentence, tokens, unigrams_count, bigrams_count)\n",
    "    bigram_prob += sentence_prob\n",
    "    \n",
    "print(bigram_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizando o cálculo da perplexidade, temos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.421179878762686\n"
     ]
    }
   ],
   "source": [
    "mean = bigram_prob/total_tokens\n",
    "perplexity = 2**(-1*(mean))\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperado, a perplexidade para bigramas é menor, mostrando que esse modelo é melhor que o unigrama."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
